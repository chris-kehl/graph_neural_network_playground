{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dgl_Graph_neural_networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8G8PeDTiiao/va8T6s6k1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chris-kehl/graph_neural_network_playground/blob/main/dgl_Graph_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is the basics of GNN's:\n",
        "Load a DGL provided dataset\n",
        "Build a GNN model with DGL provided neural network\n",
        "Train and evaluate a GNN\n",
        "Predict the category of a node in a graph\n",
        "This GNN assumes that you know the basics of pytorch"
      ],
      "metadata": {
        "id": "lT-yktPqOVRZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4csvINhN7F5",
        "outputId": "87a62b39-42fd-4bf3-ea6b-72426f027d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl==0.6.1 in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl==0.6.1) (1.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl==0.6.1) (2021.10.8)\n",
            "Requirement already satisfied: torch==1.9.1 in /usr/local/lib/python3.7/dist-packages (1.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.1) (3.10.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ],
      "source": [
        "# import all the necessary tools\n",
        "# first conda or pip install dgl\n",
        "# pytorch  1.10.0. gave me errors so i reverted to 1.9.1\n",
        "!pip install dgl==0.6.1\n",
        "!pip install torch==1.9.1\n",
        "\n",
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The node classification that we are building will consist of a semisupervised GNN for a small number of labels on a Cora dataset. This is a citation network with papers as nodes and citations as edges. The task will be to predict the category of a given paper. The nodes of each paper contains word count vectors as features. The words are normalized so that they ass up to one per the paper found at this site https://arxiv.org/abs/1609.02907 section 5.2"
      ],
      "metadata": {
        "id": "UXpbHHN3Qr7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dgl.data and get the built in dataset CoraGraphDataset\n",
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "print('Number of categories:', dataset.num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtb_hjwNQTKU",
        "outputId": "8d62c102-3e25-4f05-b4dd-58d119dcedf8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done loading data from cached files.\n",
            "Number of categories: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the Cora dataset only contains one graph\n",
        "g = dataset[0]"
      ],
      "metadata": {
        "id": "C1YnlCtPacJw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a dgl graph can store node features and edge features\n",
        "# in tow dictionary-like attributes ndata and edata\n",
        "print('Node features')\n",
        "print(g.ndata)\n",
        "print('Edge features')\n",
        "print(g.edata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6So25nea5yh",
        "outputId": "9c995771-03dd-4e57-bbd9-043a90dda8d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node features\n",
            "{'feat': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]), 'label': tensor([3, 4, 4,  ..., 3, 3, 3]), 'test_mask': tensor([False, False, False,  ...,  True,  True,  True]), 'train_mask': tensor([ True,  True,  True,  ..., False, False, False]), 'val_mask': tensor([False, False, False,  ..., False, False, False])}\n",
            "Edge features\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining a graph convolutional network**\n",
        "\n",
        "We will build a two-layer graph convolutional network(GCN)\n",
        "How this works is to stack dgl.nn.GraphConv, which are\n",
        "inherited by the torch.nn.module\n"
      ],
      "metadata": {
        "id": "Yn54iQVVbpJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "# Create the model with given dimensions\n",
        "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)"
      ],
      "metadata": {
        "id": "0D08iuDGcZf7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Graph Neural Network\n",
        "def train(g, model):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    best_val_acc = 0\n",
        "    best_test_acc = 0\n",
        "\n",
        "    features = g.ndata['feat']\n",
        "    labels = g.ndata['label']\n",
        "    train_mask = g.ndata['train_mask']\n",
        "    val_mask = g.ndata['val_mask']\n",
        "    test_mask = g.ndata['test_mask']\n",
        "    for e in range(100):\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "\n",
        "        # Compute predictions\n",
        "        pred = logits.argmax(1)\n",
        "\n",
        "        # Compute loss\n",
        "        # Note: Compute the losses only in the training set\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test acuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "        \n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}, test acc: {:.3f} (best {:.3f})'.format(\n",
        "                e, loss, val_acc, best_val_acc, test_acc, best_val_acc))\n",
        "\n",
        "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
        "train(g, model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EplGJqUjcWGj",
        "outputId": "dd30d5f9-435f-4686-fccc-370ab3f7d868"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In epoch 0, loss: 1.945, val acc: 0.206 (best 0.206, test acc: 0.227 (best 0.206)\n",
            "In epoch 5, loss: 1.890, val acc: 0.652 (best 0.656, test acc: 0.664 (best 0.656)\n",
            "In epoch 10, loss: 1.808, val acc: 0.702 (best 0.706, test acc: 0.696 (best 0.706)\n",
            "In epoch 15, loss: 1.701, val acc: 0.676 (best 0.706, test acc: 0.687 (best 0.706)\n",
            "In epoch 20, loss: 1.569, val acc: 0.718 (best 0.718, test acc: 0.708 (best 0.718)\n",
            "In epoch 25, loss: 1.415, val acc: 0.708 (best 0.718, test acc: 0.711 (best 0.718)\n",
            "In epoch 30, loss: 1.243, val acc: 0.720 (best 0.720, test acc: 0.720 (best 0.720)\n",
            "In epoch 35, loss: 1.064, val acc: 0.730 (best 0.730, test acc: 0.730 (best 0.730)\n",
            "In epoch 40, loss: 0.886, val acc: 0.752 (best 0.752, test acc: 0.744 (best 0.752)\n",
            "In epoch 45, loss: 0.722, val acc: 0.760 (best 0.760, test acc: 0.753 (best 0.760)\n",
            "In epoch 50, loss: 0.578, val acc: 0.764 (best 0.764, test acc: 0.759 (best 0.764)\n",
            "In epoch 55, loss: 0.458, val acc: 0.768 (best 0.768, test acc: 0.775 (best 0.768)\n",
            "In epoch 60, loss: 0.363, val acc: 0.766 (best 0.768, test acc: 0.779 (best 0.768)\n",
            "In epoch 65, loss: 0.289, val acc: 0.770 (best 0.770, test acc: 0.785 (best 0.770)\n",
            "In epoch 70, loss: 0.232, val acc: 0.768 (best 0.770, test acc: 0.789 (best 0.770)\n",
            "In epoch 75, loss: 0.188, val acc: 0.768 (best 0.770, test acc: 0.786 (best 0.770)\n",
            "In epoch 80, loss: 0.154, val acc: 0.772 (best 0.772, test acc: 0.789 (best 0.772)\n",
            "In epoch 85, loss: 0.129, val acc: 0.774 (best 0.774, test acc: 0.786 (best 0.774)\n",
            "In epoch 90, loss: 0.108, val acc: 0.776 (best 0.776, test acc: 0.782 (best 0.776)\n",
            "In epoch 95, loss: 0.092, val acc: 0.774 (best 0.776, test acc: 0.779 (best 0.776)\n"
          ]
        }
      ]
    }
  ]
}